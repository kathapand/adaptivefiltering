{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "228c67be",
   "metadata": {},
   "source": [
    "## Configuring filter pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c17f93",
   "metadata": {},
   "source": [
    "This Jupyter notebook explains the workflow of setting up and configuring a ground point filtering pipeline. This is an advanced workflow for users that want to define their own filtering workflows. For basic use, preconfigured pipelines are (or rather: will be) provided by `adaptivefiltering`. As always, we first need to import our library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import adaptivefiltering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e1b02",
   "metadata": {},
   "source": [
    "Also, we need to load at least one data set which we will use to interactively preview our filter settings. Note that for a good interactive experience with no downtimes, you should restrict your datasets to a reasonable size (see the working with datasets demo notebook for how to do it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb80c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = adaptivefiltering.DataSet(filename=\"data/500k_NZ20_Westport.laz\")\n",
    "dataset = adaptivefiltering.DataSet(filename=\"data/uls_thingstaette.las\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27039d1c",
   "metadata": {},
   "source": [
    "The main pipeline configuration is done by calling the `pipeline_tuning` function with your dataset as the parameter. This will open the interactive user interface which waits for your user input until you hit the *Finalize* button. The configured filter is then accessible as the Python object `pipeline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214d8d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = adaptivefiltering.pipeline_tuning(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2107f5c8",
   "metadata": {},
   "source": [
    "This pipeline can e.g. be written to disk with the following command. We typically use the extension `json` for filters. It stands for *JavaScript Object Notation* and is a widely used format for storing custom data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ec3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptivefiltering.save_filter(pipeline, \"myfilter.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34c06d8",
   "metadata": {},
   "source": [
    "In the above, we covered only the basic use of the `pipeline_tuning` function. For other use cases, additional parameters can be passed. If you want to edit an existing ground point filtering pipeline, you can load it using the `load_filter` function and then pass it to `pipeline_tuning`. The pipeline object returned by `pipeline_tuning` will be a new object - no implicit changes of the loaded pipeline object will occur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c80de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_pipeline = adaptivefiltering.load_filter(\"myfilter.json\")\n",
    "edited_pipeline = adaptivefiltering.pipeline_tuning(dataset, pipeline=old_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5f7ff8",
   "metadata": {},
   "source": [
    "If you want to inspect multiple data sets in parallel while tuning a pipeline, you can do so by passing a list of datasets to the `pipeline_tuning` function. Note that `adaptivefiltering` does currently not parallelize the execution of filter pipeline execution which may have a negative impact on wait times while tuning with multiple parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd0bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = adaptivefiltering.pipeline_tuning(datasets=[dataset, dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce62e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d675111c55b50e49d58e5179e69cc710d4110717fd214fa9e6424bfa118e8c2b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('adaptivefiltering': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
